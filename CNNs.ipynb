{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "52WBQ9Q8MazO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "PzZAY3SXMazS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "metadata": {
        "id": "0snDPFfeMazV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "metadata": {
        "id": "Z7eY_FI9MazX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "eecec204-499e-47e7-b549-ffe11dd4c2ef"
      },
      "cell_type": "code",
      "source": [
        "##Example: Loading MNIST dataset\n",
        "import keras\n",
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "40960/29515 [=========================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 9s 0us/step\n",
            "26435584/26421880 [==============================] - 9s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 4s 1us/step\n",
            "4431872/4422102 [==============================] - 4s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4N25hzdJMazf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "metadata": {
        "id": "RjNIUA0FMazf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ebd76850-78b8-4f53-c7c2-8fbc81eb2073"
      },
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6F7VcU8fMazk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agcdy54iMazn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "metadata": {
        "id": "XSle56ePMazn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99262923-cbd8-4ed8-b534-2d7f1214b573"
      },
      "cell_type": "code",
      "source": [
        "trainX[1].shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "gSbqJ7zgMazr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "metadata": {
        "id": "5Z-NDmnOMazt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(trainY)\n",
        "y_test = np_utils.to_categorical(testY)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bb-Wp56wMazx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6MnWkt7wMaz0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "metadata": {
        "id": "8ZN727bPMaz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = trainX / 255\n",
        "X_test = testX / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMZpUOn6Maz5",
        "colab_type": "code",
        "colab": {},
        "outputId": "2b226863-e6bd-4125-f9a0-bdf233bd95ee"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "RWnzc7PMMaz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "metadata": {
        "id": "iXzOi42VMaz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQaUdVBPMa0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "metadata": {
        "id": "8Sy_oRJbMa0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense, Activation,Dropout\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZu2wqqbMa0H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=30`. **"
      ]
    },
    {
      "metadata": {
        "id": "gwXpEI0oMa0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "1697931a-f486-4fd4-cc51-6c09a75d59d2"
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "#model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "#model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "#model.fit(X_train,y_train,validation_data =()X_test,Y_test),batch_size=64,epochs=30)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train,y_train,validation_data =(X_test,y_test),batch_size=64,epochs=30,  callbacks=[early_stopping])\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,222,250\n",
            "Trainable params: 3,222,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 1.5194 - acc: 0.4440 - val_loss: 1.4575 - val_acc: 0.4568\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 15s 244us/step - loss: 1.4077 - acc: 0.4795 - val_loss: 1.4590 - val_acc: 0.4609\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 15s 244us/step - loss: 1.3562 - acc: 0.4964 - val_loss: 1.4378 - val_acc: 0.4697\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 1.3078 - acc: 0.5148 - val_loss: 1.4691 - val_acc: 0.4616\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 15s 242us/step - loss: 1.2618 - acc: 0.5345 - val_loss: 1.4875 - val_acc: 0.4597\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 15s 242us/step - loss: 1.2220 - acc: 0.5494 - val_loss: 1.5130 - val_acc: 0.4593\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 1.1905 - acc: 0.5611 - val_loss: 1.5711 - val_acc: 0.4585\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 1.1662 - acc: 0.5677 - val_loss: 1.6048 - val_acc: 0.4575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8766ea9e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "KdMolOLbMa0N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "metadata": {
        "id": "g_7oehYNMa0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "8c81264f-40e1-4fc4-8d40-8ad3fab2a539"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "\n",
        "model.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train,y_train,validation_data =(X_test,y_test),batch_size=64,epochs=30,  callbacks=[early_stopping])\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 813,802\n",
            "Trainable params: 813,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 1.5353 - acc: 0.4398 - val_loss: 1.4591 - val_acc: 0.4541\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 1.4287 - acc: 0.4707 - val_loss: 1.4404 - val_acc: 0.4675\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 1.3909 - acc: 0.4842 - val_loss: 1.4281 - val_acc: 0.4702\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 15s 245us/step - loss: 1.3603 - acc: 0.4954 - val_loss: 1.4333 - val_acc: 0.4708\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 1.3348 - acc: 0.5036 - val_loss: 1.4380 - val_acc: 0.4706\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 1.3089 - acc: 0.5155 - val_loss: 1.4469 - val_acc: 0.4662\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 1.2861 - acc: 0.5240 - val_loss: 1.4580 - val_acc: 0.4681\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 1.2645 - acc: 0.5325 - val_loss: 1.4712 - val_acc: 0.4696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8766a3ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "H9KD1JxJMa0R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "metadata": {
        "id": "-92ocbROMa0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "metadata": {
        "id": "sGVeWOnPMa0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# fit parameters from data\n",
        "datagen.fit(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hE-ltSUbMa0W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "iVLV3fOoMa0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2ce63615-9c1c-4402-d0ab-16db3bf465b8"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(X_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAABuCAYAAABm4Rk8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAkhJREFUeJzt3EFuAjEUBUEccf8r/2xYZBFQ0CQ9\nEFddAOsJqccIWDMzFwAg83H2AQBgN+ILADHxBYCY+AJATHwBICa+ABATXwCIiS8AxK7Fi6y1ipf5\nV47+94nNn3dkc3s/z3u85z3eerS3my8AxMQXAGLiCwAx8QWAmPgCQEx8ASAmvgAQE18AiIkvAMTE\nFwBi4gsAMfEFgJj4AkBMfAEgJr4AEBNfAIiJLwDExBcAYuILADHxBYCY+AJATHwBICa+ABATXwCI\niS8AxMQXAGLiCwAx8QWAmPgCQEx8ASAmvgAQE18AiIkvAMTEFwBi4gsAMfEFgJj4AkBMfE8yM5eZ\nOfsYW7F5y949m7eO7C2+ABATXwCIXc8+wK7WWmcfYTs2b9m7Z/PWkb3dfAEgJr4AEBNfAIiJLwDE\nxBcAYr7t/EP3fkjt24V/x+Yte/ds3nqlvd18ASDm5nvz9Ynou6cgT6K/z+Yte/ds3nqnvd18ASAm\nvgAQ87HzzSt9HLELm7fs3bN56532dvMFgJj4AkBMfAEgJr4AEBNfAIiJLwDExBcAYuILADHxBYCY\n+AJATHwBICa+ABATXwCIiS8AxMQXAGLiCwAx8QWAmPgCQEx8ASAmvgAQE18AiIkvAMTEFwBi4gsA\nsTUzc/YhAGAnbr4AEBNfAIiJLwDExBcAYuILADHxBYCY+AJATHwBICa+ABATXwCIiS8AxMQXAGLi\nCwAx8QWAmPgCQEx8ASAmvgAQE18AiIkvAMTEFwBi4gsAMfEFgJj4AkDsE+/zU+zS0iRdAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8768a74e50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jLlv9QtYMa0b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "metadata": {
        "id": "oKM8C-YdMa0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "dc72af53-96a2-47a1-d45f-052d3f5e3524"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit_generator(datagen.flow(X_train, y_train,\n",
        "                        batch_size=64),\n",
        "                        samples_per_epoch=X_train.shape[0],\n",
        "                        nb_epoch=30,\n",
        "                        validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "  8/937 [..............................] - ETA: 16s - loss: 4.2229 - acc: 0.5215"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  import sys\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., steps_per_epoch=937, epochs=30, callbacks=[<keras.ca...)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "937/937 [==============================] - 17s 18ms/step - loss: 1.3888 - acc: 0.4965 - val_loss: 2.1398 - val_acc: 0.2964\n",
            "Epoch 2/30\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 1.2580 - acc: 0.5346 - val_loss: 2.1927 - val_acc: 0.2131\n",
            "Epoch 3/30\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 1.2333 - acc: 0.5420 - val_loss: 2.2236 - val_acc: 0.1867\n",
            "Epoch 4/30\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 1.2156 - acc: 0.5518 - val_loss: 2.2579 - val_acc: 0.1619\n",
            "Epoch 5/30\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 1.2034 - acc: 0.5562 - val_loss: 2.2724 - val_acc: 0.1348\n",
            "Epoch 6/30\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 1.1907 - acc: 0.5596 - val_loss: 2.2814 - val_acc: 0.1254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8764346c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "0P01XZ5FMa0e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "fCAIfzC2Ma0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Accuracy - 56%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsGRuvTvkmxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}